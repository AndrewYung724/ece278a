{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483a5328",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 12 Least Squares Data Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edbb83f",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "<center><img src=\"figs/02_regression.png\" alt=\"Drawing\" width=600px/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390cae36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Unit 1: Vectors, Book ILA Ch. 1-5\n",
    "\n",
    "#### Unit 2: Matrices, Book ILA Ch. 6-11 + Book IMC Ch. 2\n",
    "\n",
    "#### Unit 3: Least Squares, Book ILA Ch. 12-14\n",
    "- 11 Least Squares\n",
    "- _**12 Least Squares Data Fitting**_\n",
    "- 13 Least Squares Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4987a2d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline: 12 Least Squares Data Fitting\n",
    "\n",
    "- [Least Square Model Fitting](#sec)\n",
    "- [Validation](#sec)\n",
    "- [Feature Engineering](#sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3796889",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# True relationship: $f$\n",
    "\n",
    "\n",
    "\n",
    "$\\color{#EF5645}{\\text{Definition}}$: When we believe that a scalar $y$ and an $n$-vector $x$ are related by model:\n",
    "$$y ≈ f (x),$$\n",
    "we use the following vocabulary:\n",
    "- $x$ is called the independent variable \n",
    "- $y$ is called the outcome or response variable\n",
    "- $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}$ represents the \"true\" relationship between x and y.\n",
    "\n",
    "Generally, we do not know $f$, we just assume it exists. Our goal is to learn $f$, or a reasonable approximation of it, using data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ffe81f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "$\\color{#EF5645}{\\text{Definition}}$: The data:\n",
    "$$x^{(1)}, . . . , x^{(N)}, y^{(1)}, . . . , y^{(N)}$$\n",
    "are called observations, examples, samples, or measurements.\n",
    "- $x^{(i)}, y^{(i)}$ is ith data pair\n",
    "- $x^{(i)}_j$ is the jth component of ith data point $x^{(i)}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c15a12",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model: $\\hat{f}$\n",
    "\n",
    "$\\color{#EF5645}{\\text{Definition}}$: Choosing a set of basis functions: $f_i: \\mathbb{R}^n \\rightarrow \\mathbb{R}$, for $i=1...p$, we model a guess or approximation of $f$ as:\n",
    "$$\\hat{f}(x) = \\theta_1 f_1(x) + ... + \\theta_p f_p(x),$$\n",
    "where:\n",
    "- $\\theta_i$ are model parameters that we will learn from the data,\n",
    "- $\\hat{y}^{(i)} = \\hat{f}(x^{(i)})$ is (the model’s) prediction of $y^{(i)}$.\n",
    "\n",
    "\n",
    "$\\color{#EF5645}{\\text{Remark}}$: If our model is good, then $\\hat{y}^{(i)} ≈ y^{(i)},$ i.e., model is consistent with observed data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e3c30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Residuals\n",
    "\n",
    "$\\color{#EF5645}{\\text{Definition}}$: Given:\n",
    "- observations $x^{(1)}, ..., x^{(N)},..., y^{(1)}, y^{(N)}$,\n",
    "- a model $\\hat{f}$ generating $\\hat{y}^{(i)} = \\hat{f}(x^{(i)})$ predictions of $y^{(i)}$, for $i=1, ..., p$,\n",
    "\n",
    "we define the prediction error, or residual: \n",
    "$$r_i = y^{(i)} - \\hat{y}^{(i)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74860a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Least Square Data Fitting\n",
    "\n",
    "$\\color{#EF5645}{\\text{Definition}}$: The Least Square Data Fitting problem is the problem of choosing model's parameters $\\theta_1, ..., \\theta_n$ that minimize the RMS prediction error on the dataset:\n",
    "$$\\left(\\frac{r_1^2 + ... + r_N^2}{N}\\right)^{1/2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0220e2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LS Data Fitting and LS\n",
    "\n",
    "The Least Square (LS) Data Fitting problem can be formulated as a Least Squares (LS) Problem.\n",
    "\n",
    "$\\color{#EF5645}{\\text{Notations}}$: We can express $y^{(i)}, \\hat{y}^{(i)}$, and $r_i$ as $N$-vectors:\n",
    "- $y = (y^{(1)}, . . . , y^{(N)})$ is vector of outcomes,\n",
    "- $\\hat{y} = (\\hat y^{(1)}, . . . , \\hat  y^{(N)})$ is vector of predictions,\n",
    "- $r = (r_1, . . . , r_N)$ is vector of residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd786b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\color{#6D7D33}{\\text{Proposition}}$: Define the $N \\times p$ matrix $A$ with elements $A_{ij} = f_j(x^{(i)})$, such that $\\hat y =A \\theta$. The least square data fitting problem amounts to choose $\\theta$ that minimizes:\n",
    "$$||A\\theta - y||^2,$$\n",
    "which shows that it can be written as a Least Square Problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9ccea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Solving the LS Data Fitting Problem\n",
    "\n",
    "$\\color{#6D7D33}{\\text{Proposition}}$: Consider a LS Data Fitting problem formulated as minimizing $||A \\theta - y||^2$. Assuming that the columns of $A$ are independent, the solution is:\n",
    "$$\\hat \\theta = (A^TA)^{-1}A^Ty.$$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
