{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c7f2404",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 09 Matrix Multiplication\n",
    "\n",
    "<center><img src=\"figs/09_six_degrees.png\" alt=\"default\" width=600px/></center>\n",
    "\n",
    "<center>Six degrees of separation theory</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f746c1b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Unit 1: Vectors, Book ILA Ch. 1-5\n",
    "\n",
    "#### Unit 2: Matrices, Book ILA Ch. 6-11 + Book IMC Ch. 2\n",
    "- 06 Matrices\n",
    "- 07 Linear Equations\n",
    "- 08 Linear Dynamical Systems\n",
    "- **_09 Matrix Multiplication_**\n",
    "- 10 Matrix Inverse\n",
    "\n",
    "#### Unit 3: Least Squares, Book ILA Ch. 12-14 + Book IMC Ch. 8\n",
    "#### Unit 4: Eigen-decomposition, Book IMC Ch. 10, 12, 19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f68af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline: 09 Matrix Multiplication\n",
    "\n",
    "- **[Matrix Multiplication](#sec-matrices)**\n",
    "- [Composition of linear functions](#sec-matrices)\n",
    "- [Matrix powers](#sec-matrices)\n",
    "- [QR factorization](#sec-matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d904b7f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matrix Multiplication\n",
    "\n",
    "$\\color{#EF5645}{\\text{Definition}}$: Consider $m \\times p$ matrix $A$ and $p \\times n$ matrix $B$. The matrix multiplication, written $C = AB$ is defined as:\n",
    "$$C_{ij} = \\sum_{k=1}^p  A_{ik}B_{kj} \\text{ for } i= 1, ...m , j = 1, ...n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f9544",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Special Cases of Matrix Multiplication\n",
    "\n",
    "For $\\alpha$ a scalar, $x, y$ vectors, and $A$ a matrix:\n",
    "- vector-scalar product, i.e. $x \\alpha$ (note that $\\alpha$ is on the right!)\n",
    "- inner-product $x^T y$\n",
    "- matrix vector multiplication $Ax$\n",
    "\n",
    "$\\color{#EF5645}{\\text{Definition}}$: The outer product of $m$-vector $x$ and $n$-vector $y$ is defined as $xy^T$, and is a special case of matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5415f177",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Properties\n",
    "\n",
    "$\\color{#6D7D33}{\\text{Properties}}$: For matrices $A, B, C$ and identity matrix $I$:\n",
    "- Associativity: $(AB)C = A(BC)$\n",
    "- Distributivity: $A(B+C)  = AB + AC$\n",
    "- $(AB)^T = B^T A^T$\n",
    "- $AI = A$ and $IA = A$.\n",
    "\n",
    "$\\color{#EF5645}{\\text{Important remark}}$: $AB = BA$ does NOT hold in general. We say that the matrix multiplication is NOT commutative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e20395e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercises\n",
    "\n",
    "$\\color{#047C91}{\\text{Exercise}}$: Let $A$ be a matrix and $I$ be the identity matrix. Show that $AI = A$.\n",
    "\n",
    "$\\color{#047C91}{\\text{Exercise}}$: Given $m$-vector $x$ and $n$-vector $y$, write the outer product $xy^T$ using the entries of $x$ and $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9582cab5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\color{#003660}{\\text{In Python}}$, we us `np.matmul` or `@` to compute the matrix multiplication. Verify that the matrix multiplication is generally NOT communitative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e41a7420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17 19]\n",
      " [-9 -3]]\n",
      "[[17 19]\n",
      " [-9 -3]]\n",
      "[[  0   6]\n",
      " [-20  14]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([[1, 2],[-3, 0]])\n",
    "B = np.array([[3, 1], [7, 9]])\n",
    "print(np.matmul(A, B))\n",
    "print(A @ B)\n",
    "print(B @ A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe0f09",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inner-product interpretation\n",
    "\n",
    "$\\color{#6D7D33}{\\text{Properties}}$: Consider matrices $A, B$ with $a_i^T$ the rows of $A$ nd $b_j$ the columns of $B$. We have: \n",
    "$$AB = \\begin{bmatrix}\n",
    "a_1^Tb_1 & a_1^Tb_2 & ... & a_1^T b_n \\\\\n",
    "a_2^Tb_1 & a_2^Tb_2 & ... & a_2^T b_n \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_m^Tb_1 & a_m^Tb_2 & ... & a_m^T b_n\n",
    "\\end{bmatrix}$$\n",
    "The matrix product gathers the inner-products of rows of $A$ and columns of $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8a1f11",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Building Matrices from Matrices\n",
    "\n",
    "$\\color{#EF5645}{\\text{Definition}}$: Let $A$ be an $m \\times n$ matrix with columns $a_1, .., a_n$. The Gram matrix $G$ of $A$ is:\n",
    "$$ G = A^T A = \\begin{bmatrix}\n",
    "a_1^Ta_1 & a_1^Ta_2 & ... & a_1^T a_n \\\\\n",
    "a_2^Ta_1 & a_2^Ta_2 & ... & a_2^T a_n \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "a_n^Ta_1 & a_n^Ta_2 & ... & a_n^T a_n\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$\\color{#6D7D33}{\\text{Properties}}$:\n",
    "- The Gram matrix gives all inner products of columns of $A$\n",
    "- If $G = I$ then the columns of $A$ are orthonormal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49824477",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline: 09 Matrix Multiplication\n",
    "\n",
    "- [Matrix Multiplication](#sec-matrices)\n",
    "- **[Composition of linear functions](#sec-matrices)**\n",
    "- [Matrix powers](#sec-matrices)\n",
    "- [QR factorization](#sec-matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb489d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\color{#EF5645}{\\text{Definition}}$: Consider $f: \\mathbb{R}^p \\rightarrow \\mathbb{R}^m$ and $g: \\mathbb{R}^n \\rightarrow \\mathbb{R}^p$. The function $h: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ defined as: $h(x) = f(g(x))$ for all $x \\in \\mathbb{R}^n$ is called the composition of $f$ and $g$.\n",
    "\n",
    "$\\color{#EF5645}{\\text{Definition}}$: Assume functions $f, g$ are linear functions, thus can be written as: $f(u) = Au$ and $g(x)=Bx$ for $n$-vector $x$ and $p$-vector $u$. Then the composition $h$ can be written as: $h(x) = (AB)x$.\n",
    "\n",
    "$\\color{#EF5645}{\\text{Remark}}$: This means that:\n",
    "- the composition of linear functions is a linear function\n",
    "- the associated matrix is product of matrices of the functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055e3eab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: Second Difference Matrices\n",
    "\n",
    "$\\color{#047C91}{\\text{Example}}$: Consider $D_n$ the $(n-1)\\times n$ difference matrix such that:\n",
    "$$ D_n x = (x_2 - x_1, ..., x_n - x_{n-1}),$$\n",
    "and $D_{n-1}$ the $(n-2) \\times (n-1)$ different matrix such that:\n",
    "$$ D_{n-1} y = (y_2 - y_1, ..., y_{n-1} - y_{n-2}).$$\n",
    "Then $\\Delta = D_{n-1}D_n$ is called the $(n-2) \\times n$ second difference matrix:\n",
    "$$\\Delta x = (x_2 - 2x_1 + x_3, ..., x_n  - 2 x_{n-1} + x_n).$$\n",
    "\n",
    "Compute $\\Delta$ for $n=5$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56578398",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline: 09 Matrix Multiplication\n",
    "\n",
    "- [Matrix Multiplication](#sec-matrices)\n",
    "- [Composition of linear functions](#sec-matrices)\n",
    "- **[Matrix powers](#sec-matrices)**\n",
    "- [QR factorization](#sec-matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2172fc56",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Matrix Power\n",
    "\n",
    "$\\color{#EF5645}{\\text{Definition}}$: The square of a matrix $A$, written $A^2$ is defined as: $A^2 = AA$.\n",
    "\n",
    "$\\color{#EF5645}{\\text{Definition}}$: For a positive integrer $k$, the $k$th power of a matrix $A$, written $A^k$ is defined as: $A^k = A...A$ with $k$ matrices $A$ multiplied. By convention, $A^0 = I$ the identity matrix.\n",
    "\n",
    "$\\color{#6D7D33}{\\text{Property}}$: For integers $k, l$ we have: $A^kA^l = A^{k+l}$.\n",
    "\n",
    "$\\color{#EF5645}{\\text{Remark}}$: We will see negative integers later; fractional integers will be seen in other courses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957dcbbf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: Directed graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df5ed4e",
   "metadata": {},
   "source": [
    "$\\color{#047C91}{\\text{Example}}$: Consider the adjacency matrix associated to the directed graph:\n",
    "\n",
    "<center><img src=\"figs/09_adjacency.png\" alt=\"default\", width=600px/></center>\n",
    "\n",
    "- $(A^2)_{ij}$ is the number of paths of length 2 going from $j$ to $i$,\n",
    "- $(A^l)_{ij}$ is the number of paths of length $l$ going from $j$ to $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a405fee4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\color{#047C91}{\\text{Example}}$: Give an idea on how to prove the six degrees separation theory.\n",
    "\n",
    "<center><img src=\"figs/09_six_degrees.png\" alt=\"default\" width=700px/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cef310e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\color{#047C91}{\\text{Example}}$: Consider an epidemic modeled by the SIR linear dynamical model with dynamic matrix $A$. What is $A^k x_0$ where $x_0$ is the initial state?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e3443",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline: 09 Matrix Multiplication\n",
    "\n",
    "- [Matrix Multiplication](#sec-matrices)\n",
    "- [Composition of linear functions](#sec-matrices)\n",
    "- [Matrix powers](#sec-matrices)\n",
    "- **[QR factorization](#sec-matrices)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725c81cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# QR Factorization\n",
    "\n",
    "$\\color{#EF5645}{\\text{Proposition}}$: Any matrix $A$ can be decomposed into two matrices $Q, R$ such that $A = QR$ and:\n",
    "- $Q$ is a matrix such that: $Q^TQ = I$\n",
    "- $R$ is a upper triangular matrix.\n",
    "\n",
    "$\\color{#EF5645}{\\text{Remark}}$: We will not learn how to compute it manually. We will rather learn how to compute it in Python, and use it in practice... for example to solve any type of linear equations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e982f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\color{#003660}{\\text{In Python}}$, the QR decomposition of a matrix $A$ can be computed using `np.linalg.qr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b0c1b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5012f043",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline: 09 Matrix Multiplication\n",
    "\n",
    "- [Matrix Multiplication](#sec-matrices)\n",
    "- [Composition of linear functions](#sec-matrices)\n",
    "- [Matrix powers](#sec-matrices)\n",
    "- **[QR factorization](#sec-matrices)**\n",
    "\n",
    "Resources: Book ILA Ch. 10"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
